{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- encoding: utf-8 -*-\n",
    "from __future__ import print_function  \n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer  \n",
    "from keras.preprocessing.sequence import pad_sequences  \n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.layers import Dense, Input, Flatten,Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding  \n",
    "from keras.models import Model  \n",
    "from keras.optimizers import *  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainModel(data,modelFile,cnn_mdl):\n",
    "    # 划分数据集\n",
    "    X =data[:,:-1]\n",
    "    y =data[:,-1]\n",
    "    \n",
    "    print(\"shape of X:\",X.shape)\n",
    "    print(\"shape of y:\",y.shape)\n",
    "    \n",
    "    train_set,test_set,train_tag,test_tag = train_test_split(X,y,test_size = 0.3)\n",
    "    \n",
    "    # 把一维的标签做onehot，pd.get_dummies的结果是df,把df转为ndarray (as_matrix())\n",
    "    train_label = pd.get_dummies(train_tag).as_matrix()\n",
    "    test_label = pd.get_dummies(test_tag).as_matrix()\n",
    "    \n",
    "    print('shape of train set:',train_set.shape)\n",
    "    print('shape of train label:',train_label.shape)\n",
    "    print('shape of test set:',test_set.shape)\n",
    "    print('shape of test label:',test_label.shape)\n",
    "    \n",
    "    # 读入模型   \n",
    "    model = models.Word2Vec.load(modelFile)\n",
    "    # 读入word2vec模型提供的嵌入层，权重需要训练\n",
    "    model_embedding = model.wv.get_embedding_layer(train_embeddings=False)\n",
    "\n",
    "    # 训练嵌入层权重\n",
    "    kmodel = Sequential()\n",
    "    kmodel.add(model_embedding)\n",
    "    kmodel.compile('rmsprop', 'mse')\n",
    "    \n",
    "#     print(model_embedding.get_weights())\n",
    "    \n",
    "    # 定义嵌入层\n",
    "    # trainable=True 通过训练来更新权重\n",
    "    # trainable=Fasle 由于使用了word2vec提供的权重，这里不用再训练了\n",
    "    embedding_layer = Embedding(input_dim = model_embedding.input_dim,\n",
    "                                output_dim = 200,\n",
    "                                input_length = 200,\n",
    "                                weights = model_embedding.get_weights(),\n",
    "                                trainable = False)\n",
    "    \n",
    "    model_left = Sequential() \n",
    "    \n",
    "    # 使用word2vec训练好的嵌入层\n",
    "    model_left.add(embedding_layer)\n",
    "    \n",
    "    model_left.add(Conv1D(64, 3, padding='same',activation='relu')) \n",
    "    model_left.add(MaxPooling1D(3)) \n",
    "    model_left.add(Conv1D(64, 3, padding='same',activation='relu')) \n",
    "    model_left.add(MaxPooling1D(3)) \n",
    "    model_left.add(Conv1D(64, 3, padding='same',activation='relu')) \n",
    "    model_left.add(MaxPooling1D(18))\n",
    "    model_left.add(Flatten())\n",
    " \n",
    "    model_right = Sequential() \n",
    "    \n",
    "    # 使用word2vec训练好的嵌入层\n",
    "    model_right.add(embedding_layer)\n",
    "    \n",
    "    model_right.add(Conv1D(64, 4, padding='same',activation='relu')) \n",
    "    model_right.add(MaxPooling1D(4)) \n",
    "    model_right.add(Conv1D(64, 4, padding='same',activation='relu')) \n",
    "    model_right.add(MaxPooling1D(4)) \n",
    "    model_right.add(Conv1D(64, 4, padding='same',activation='relu')) \n",
    "    model_right.add(MaxPooling1D(12))\n",
    "    model_right.add(Flatten()) \n",
    "    \n",
    "    model_cent = Sequential() \n",
    "    \n",
    "    # 使用word2vec训练好的嵌入层\n",
    "    model_cent.add(embedding_layer)\n",
    "    \n",
    "    model_cent.add(Conv1D(64, 5, padding='same',activation='relu')) \n",
    "    model_cent.add(MaxPooling1D(5)) \n",
    "    model_cent.add(Conv1D(64, 5, padding='same',activation='relu')) \n",
    "    model_cent.add(MaxPooling1D(5)) \n",
    "    model_cent.add(Conv1D(64, 5, padding='same',activation='relu')) \n",
    "    model_cent.add(MaxPooling1D(8))\n",
    "    model_cent.add(Flatten()) \n",
    "    \n",
    "    merged = Merge([model_left, model_right,model_cent], mode='concat') \n",
    "    \n",
    "    # 最终                       \n",
    "    model = Sequential() \n",
    "                   \n",
    "    model.add(merged)\n",
    "    model.add(Dense(128, activation='relu')) # 全连接层  \n",
    "    model.add(Dense(2, activation='softmax')) # softmax，输出文本属于20种类别中每个类别的概率  \n",
    "        \n",
    "    # 优化器我这里用了adadelta，也可以使用其他方法  \n",
    "    model.compile(loss='categorical_crossentropy',  \n",
    "                  optimizer='Adadelta',  \n",
    "                  metrics=['accuracy'])  \n",
    "\n",
    "    # =下面开始训练，nb_epoch是迭代次数，可以高一些，训练效果会更好，但是训练会变慢  \n",
    "    model.fit(train_set, train_label,epochs=10,batch_size = 100)  \n",
    "\n",
    "    score = model.evaluate(train_set, train_label, verbose=0) # 评估模型在训练集中的效果，准确率约99%  \n",
    "    print('train score:', score[0])  \n",
    "    print('train accuracy:', score[1])  \n",
    "    \n",
    "    score = model.evaluate(test_set,test_label, verbose=0)  # 评估模型在测试集中的效果，准确率约为97%，迭代次数多了，会进一步提升  \n",
    "    print('Test score:', score[0])  \n",
    "    print('Test accuracy:', score[1]) \n",
    "    \n",
    "    model.save(cnn_mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # 定义文件路径\n",
    "    dataPath = \"/home/hadoop/DataSencise/bdci2017/BDCI2017-360/data/\"\n",
    "    mdlPath = \"/home/hadoop/DataSencise/bdci2017/BDCI2017-360/model/\"\n",
    "    \n",
    "    inFile = [dataPath + \"train/train_m\"+ str(x) + \".npy\" for x in range(1,6)]\n",
    "    \n",
    "    modelFile = [mdlPath + \"w2v_m\"+ str(x) + \".mdl\" for x in range(1,6)]\n",
    "    \n",
    "    cnn_mdl = [mdlPath + \"cnn_m\"+ str(x) + \".mdl\" for x in range(1,6)]\n",
    "    \n",
    "#     for (tf,mfncf) in zip(inFile,modelFile,cnn_mdl):\n",
    "#         data = np.load(tf)\n",
    "#         # 训练模 \n",
    "#         trainModel(data,mf,cf)  \n",
    "    \n",
    "    data = np.load(inFile[0])\n",
    "    trainModel(data,modelFile[0],cnn_mdl[0])\n",
    "    \n",
    "    # 测试模型\n",
    "#     useModel(modelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
